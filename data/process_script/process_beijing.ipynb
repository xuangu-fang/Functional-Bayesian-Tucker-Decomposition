{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import glob\n",
                "import matplotlib.pyplot as plt\n",
                "import collections\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   year  month  day       station      TEMP         PRES       DEWP  RAIN wd  \\\n",
                        "0  2013      3    1  Aotizhongxin  1.391667  1026.875000 -18.745833   0.0  N   \n",
                        "1  2013      3    1     Changping  0.812500  1023.858333 -19.583333   0.0  N   \n",
                        "2  2013      3    1      Dingling -0.950000  1024.025000 -19.625000   0.0  N   \n",
                        "3  2013      3    1        Dongsi  1.728571  1029.152381 -20.980952   0.0  N   \n",
                        "4  2013      3    1      Guanyuan  1.391667  1026.875000 -18.745833   0.0  N   \n",
                        "\n",
                        "       WSPM     PM2.5       PM10        SO2        NO2          CO         O3  \n",
                        "0  3.254167  7.125000  10.750000  11.708333  22.583333  429.166667  63.875000  \n",
                        "1  2.133333  5.083333  18.958333  16.041667  15.333333  387.500000  77.791667  \n",
                        "2  2.337500  6.250000   7.250000   3.000000   2.625000  212.500000  78.875000  \n",
                        "3  3.142857  6.714286  10.666667   8.714286  29.571429  409.523810  72.857143  \n",
                        "4  3.254167  7.541667  11.666667   8.500000  28.500000  400.000000  63.166667  \n"
                    ]
                }
            ],
            "source": [
                "np.random.seed(0)\n",
                "\n",
                "path = r'/data/fang/data/Beijing/4x6x12x6/PRSA_Data_20130301-20170228' # use your path\n",
                "all_files = glob.glob(path + \"/*.csv\")\n",
                "\n",
                "li = []\n",
                "\n",
                "for filename in all_files:\n",
                "    df = pd.read_csv(filename, index_col=None, header=0)\n",
                "    li.append(df)\n",
                "\n",
                "frame = pd.concat(li, axis=0, ignore_index=True)\n",
                "\n",
                "df = frame[['year', 'month', 'day', 'hour', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM', 'station', 'PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']]\n",
                "df = df.dropna()\n",
                "# print(df.head())\n",
                "df = df.groupby(['year', 'month', 'day', 'station']).agg({'TEMP':'mean', 'PRES':'mean', 'DEWP':'mean', 'RAIN':'mean', 'wd':lambda x: collections.Counter(''.join(x)).most_common(2)[0][0], 'WSPM':'mean', 'PM2.5':'mean', 'PM10':'mean', 'SO2':'mean', 'NO2':'mean', 'CO':'mean', 'O3':'mean'}).reset_index()\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "36.98571428571428 -15.691304347826087\n",
                        "11.108333333333334 0.0\n",
                        "1041.0249999999999 985.6\n",
                        "27.616666666666664 -33.020833333333336\n",
                        "7.2375 0.0\n",
                        "1461\n"
                    ]
                }
            ],
            "source": [
                "print(df['TEMP'].max(), df['TEMP'].min()) # 4\n",
                "print(df['RAIN'].max(), df['RAIN'].min()) # 3\n",
                "print(df['PRES'].max(), df['PRES'].min()) # 3\n",
                "print(df['DEWP'].max(), df['DEWP'].min()) # 3\n",
                "print(df['WSPM'].max(), df['WSPM'].min()) # 3\n",
                "# print(df['PM2.5'].max(), df['PM2.5'].min())\n",
                "# print(df.shape)\n",
                "\n",
                "df['time'] = pd.to_datetime(df[['year', 'month', 'day']]).astype(np.int64) // 10 ** 9 \n",
                "\n",
                "df['time'] =(df['time'] - df['time'].mean())/(df['time'].std())\n",
                "print(len(df['time'].unique()))\n",
                "len(df)\n",
                "\n",
                "df['PM2.5'] = (df['PM2.5'] - df['PM2.5'].mean()) / df['PM2.5'].std() \n",
                "df['PM10'] = (df['PM10'] - df['PM10'].mean()) / df['PM10'].std() \n",
                "df['SO2'] = (df['SO2'] - df['SO2'].mean()) / df['SO2'].std()\n",
                "df['NO2'] = (df['NO2'] - df['NO2'].mean()) / df['NO2'].std()\n",
                "df['CO'] = (df['CO'] - df['CO'].mean()) / df['CO'].std()\n",
                "df['O3'] = (df['O3'] - df['O3'].mean()) / df['O3'].std()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "decimal: 1  TEMP 428\n",
                        "decimal: 1  PRES 501\n",
                        "decimal: 1  RAIN 46\n",
                        "decimal: 1  DEWP 558\n",
                        "decimal: 3  time 1461\n",
                        "16965\n"
                    ]
                }
            ],
            "source": [
                "def make_continues_mode(df, mode, decimals=1, normalize=10):\n",
                "\n",
                "    target_df = df[mode].round(decimals)\n",
                "    if normalize:\n",
                "        df[mode+'_CONTI'] = normalize* (target_df-target_df.min())/(target_df.max()-target_df.min())\n",
                "\n",
                "    df[mode+'_DISCT'],CONTI_2_DISCT_dict,DISCT_2_CONTI_dict = unique_recoding(df[mode+'_CONTI'])\n",
                "    print('decimal: %d '%(decimals),mode,len(df[mode+'_DISCT'].unique()))\n",
                "\n",
                "    return CONTI_2_DISCT_dict,DISCT_2_CONTI_dict\n",
                "\n",
                "def unique_recoding(target_df):\n",
                "    # colum_name = 'movieId'\n",
                "    unique_key = np.sort(target_df.unique())\n",
                "    CONTI_2_DISCT_dict = {key:id for id,key in enumerate(unique_key)}\n",
                "    DISCT_2_CONTI_dict = {id:key for id,key in enumerate(unique_key)}\n",
                "\n",
                "\n",
                "    new_column = target_df.apply(lambda x:CONTI_2_DISCT_dict[x])\n",
                "    # data[colum_name] = new_column\n",
                "    # print('ndim of %s is %d'%(colum_name,len(new_column.unique())))\n",
                "    return new_column,CONTI_2_DISCT_dict,DISCT_2_CONTI_dict\n",
                "\n",
                "CONTI_2_DISCT_dict_list = {}\n",
                "DISCT_2_CONTI_dict_list = {}\n",
                "for mode in ['TEMP','PRES','RAIN','DEWP']:\n",
                "    CONTI_2_DISCT_dict, DISCT_2_CONTI_dict = make_continues_mode(df,mode, decimals=1, normalize=10)\n",
                "    CONTI_2_DISCT_dict_list[mode] = CONTI_2_DISCT_dict\n",
                "    DISCT_2_CONTI_dict_list[mode] = DISCT_2_CONTI_dict\n",
                "    \n",
                "mode = 'time'\n",
                "CONTI_2_DISCT_dict, DISCT_2_CONTI_dict = make_continues_mode(df,mode, decimals=3, normalize=10)\n",
                "CONTI_2_DISCT_dict_list[mode] = CONTI_2_DISCT_dict\n",
                "DISCT_2_CONTI_dict_list[mode] = DISCT_2_CONTI_dict\n",
                "\n",
                "print(len(df))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_disct_data(modes_BASE,dims_BASE,target_pollute):\n",
                "    df_base = df.copy()\n",
                "\n",
                "    # df_DISCT = df.groupby(['year', 'month', 'day', 'station']).agg({'TEMP':'mean', 'PRES':'mean', 'DEWP':'mean', 'RAIN':'mean', 'wd':lambda x: collections.Counter(''.join(x)).most_common(2)[0][0] + collections.Counter(''.join(x)).most_common(2)[1][0], 'WSPM':'mean', 'PM2.5':'mean'}).reset_index()\n",
                "\n",
                "    for i in range(len(dims_BASE)):\n",
                "        target_mode = modes_BASE[i]\n",
                "        DISCT_dim = dims_BASE[i]\n",
                "        df_base[target_mode + '_BASE'] = pd.cut( df_base[target_mode +'_CONTI'], DISCT_dim).astype('category').cat.codes \n",
                "\n",
                "    target_modes_BASE = [ item + '_BASE' for item in modes_BASE]\n",
                "\n",
                "    # df_base = df_base.groupby(target_modes_BASE).agg({target_pollute:'mean'}).reset_index()\n",
                "\n",
                "    ndims = [df_base[mode].max()+1 for mode in target_modes_BASE]\n",
                "    \n",
                "\n",
                "    N = len(df_base)\n",
                "    print(ndims, ' N=',N)\n",
                "    Ntr = int(N * 0.8)\n",
                "    idx = np.arange(N)\n",
                "    folds = []\n",
                "\n",
                "    for i in range(5):\n",
                "        np.random.shuffle(idx)\n",
                "        tr_idx = idx[:Ntr]\n",
                "        tr_y = df_base[target_pollute][tr_idx].values\n",
                "        tr_ind = df_base[target_modes_BASE].values[tr_idx,:]\n",
                "        \n",
                "        # print('fold=',i)\n",
                "\n",
                "        te_idx = idx[Ntr:]\n",
                "        te_y = df_base[target_pollute][te_idx].values\n",
                "        te_ind = df_base[target_modes_BASE].values[te_idx,:]\n",
                "\n",
                "\n",
                "        folds.append({\n",
                "            'tr_ind': tr_ind,\n",
                "            'tr_y': tr_y,\n",
                "            'te_ind': te_ind,\n",
                "            'te_y': te_y,\n",
                "            'ndims':ndims,\n",
                "        })\n",
                "\n",
                "    data = {'ndims': ndims, 'data': folds}\n",
                "    ndim_str = \"x\".join([str(i) for i in ndims])\n",
                "\n",
                "    print()\n",
                "\n",
                "    # dict_name = '../beijing/'+'_'.join(modes_BASE)+'_'+target_pollute+'/'\n",
                "    dict_name = '../beijing/'+'beijing_'+target_pollute+'/'\n",
                "\n",
                "    Path(dict_name).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    # file_name = 'DISCT_' + ndim_str+'_no_agg'+'.npy'\n",
                "    file_name = 'DISCT_' + ndim_str+'.npy'\n",
                "\n",
                "    # print(file_name)\n",
                "    np.save(dict_name + file_name, data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[50, 50, 150]  N= 16965\n",
                        "\n",
                        "[100, 100, 300]  N= 16965\n",
                        "\n",
                        "[300, 300, 1000]  N= 16965\n",
                        "\n",
                        "[428, 501, 1461]  N= 16965\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# discretized data with different granularity, use for baseline \n",
                "target_pollute = 'PM2.5'\n",
                "modes_BASE = ['TEMP','PRES','time']\n",
                "dims_BASE = [50,50,50]\n",
                "# dims_BASE = [428,501,1461] # full\n",
                "\n",
                "# target_pollute_list = ['PM2.5','PM10','SO2']\n",
                "target_pollute_list = ['PM10']\n",
                "\n",
                "dims_BASE_list = [[50,50,150],[100,100,300],[300,300,1000],[428,501,1461] ]\n",
                "\n",
                "for target_pollute in target_pollute_list:\n",
                "    for dims_BASE in dims_BASE_list: \n",
                "        \n",
                "        process_disct_data(modes_BASE,dims_BASE,target_pollute)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[50, 50, 150]  N= 7455\n",
                        "\n",
                        "[100, 100, 300]  N= 10320\n",
                        "\n",
                        "[300, 300, 1000]  N= 11746\n",
                        "\n",
                        "[428, 501, 1461]  N= 11954\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "'''agg-version'''\n",
                "\n",
                "# discretized data with different granularity, use for baseline \n",
                "# target_pollute = 'PM2.5'\n",
                "# modes_BASE = ['TEMP','PRES','time']\n",
                "# dims_BASE = [50,50,50]\n",
                "# # dims_BASE = [428,501,1461] # full\n",
                "\n",
                "# # target_pollute_list = ['PM2.5','PM10','SO2']\n",
                "# target_pollute_list = ['PM10']\n",
                "\n",
                "# dims_BASE_list = [[50,50,150],[100,100,300],[300,300,1000],[428,501,1461] ]\n",
                "\n",
                "# for target_pollute in target_pollute_list:\n",
                "#     for dims_BASE in dims_BASE_list:\n",
                "        \n",
                "#         process_disct_data(modes_BASE,dims_BASE,target_pollute)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_conti_data(target_pollute,target_modes):\n",
                "    modes_DISCT = [mode+'_DISCT' for mode in target_modes]\n",
                "    modes_CONTI = [mode+'_CONTI' for mode in target_modes]\n",
                "\n",
                "    CONTI_2_DISCT_dicts = [CONTI_2_DISCT_dict_list[mode] for mode in target_modes]\n",
                "    DISCT_2_CONTI_dicts = [DISCT_2_CONTI_dict_list[mode] for mode in target_modes]\n",
                "\n",
                "\n",
                "    ndims = [df[mode].max()+1 for mode in modes_DISCT]\n",
                "    print('ndims:',ndims)\n",
                "\n",
                "    N = len(df)\n",
                "    Ntr = int(N * 0.8)\n",
                "    idx = np.arange(N)\n",
                "    folds = []\n",
                "    for i in range(5):\n",
                "        np.random.shuffle(idx)\n",
                "        tr_idx = idx[:Ntr]\n",
                "        tr_y = df[target_pollute][tr_idx].values\n",
                "        tr_ind_DISCT = df[modes_DISCT].values[tr_idx,:]\n",
                "        tr_ind_CONTI = df[modes_CONTI].values[tr_idx,:]\n",
                "\n",
                "        # print('fold=',i)\n",
                "        # print(len(np.unique(tr_ind_DISCT[:,0])))\n",
                "        # print(len(np.unique(tr_ind_DISCT[:,1])))\n",
                "        # print(len(np.unique(tr_ind_DISCT[:,2])))\n",
                "\n",
                "        te_idx = idx[Ntr:]\n",
                "        te_y = df[target_pollute][te_idx].values\n",
                "        te_ind_DISCT = df[modes_DISCT].values[te_idx,:]\n",
                "        te_ind_CONTI = df[modes_CONTI].values[te_idx,:]\n",
                "\n",
                "        # track the never-seen idx in test data\n",
                "        never_seen_test_idx = []\n",
                "        for mode in range(len(target_modes)):\n",
                "            train_set = set(np.unique(tr_ind_DISCT[:,mode]))\n",
                "            full_set = set(DISCT_2_CONTI_dicts[mode].keys())\n",
                "            never_seen_test_idx.append(list(full_set.difference(train_set)))\n",
                "\n",
                "\n",
                "        folds.append({\n",
                "            'tr_ind_DISCT': tr_ind_DISCT,\n",
                "            'tr_ind_CONTI': tr_ind_CONTI,\n",
                "            'tr_y': tr_y,\n",
                "            'te_ind_DISCT': te_ind_DISCT,\n",
                "            'te_ind_CONTI': te_ind_CONTI,\n",
                "            'te_y': te_y,\n",
                "            'ndims':ndims,\n",
                "            'never_seen_test_idx':never_seen_test_idx\n",
                "        })\n",
                "\n",
                "    data = {'ndims': ndims, 'data': folds,'CONTI_2_DISCT_dicts':CONTI_2_DISCT_dicts, 'DISCT_2_CONTI_dicts':DISCT_2_CONTI_dicts}\n",
                "    ndim_str = \"x\".join([str(i) for i in ndims])\n",
                "\n",
                "    # dict_name = '../beijing/'+'_'.join(target_modes)+'_'+target_pollute+'/'\n",
                "    dict_name = '../beijing/'+'beijing_'+target_pollute+'/'\n",
                "\n",
                "\n",
                "    Path(dict_name).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    file_name = 'CONTI_' + ndim_str +'.npy'\n",
                "\n",
                "\n",
                "    # file_name = 'conti_beijing_15k_'+'_'.join(target_modes)+'_'+target_pollute+'_'+ndim_str+'.npy'\n",
                "    print(file_name)\n",
                "    np.save(dict_name + file_name, data)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ndims: [428, 501, 1461]\n",
                        "CONTI_428x501x1461.npy\n"
                    ]
                }
            ],
            "source": [
                "# target_pollute_list = ['PM2.5','PM10','NO2']\n",
                "target_pollute_list = ['PM10']\n",
                "\n",
                "target_modes = ['TEMP','PRES','time']\n",
                "\n",
                "\n",
                "for target_pollute in target_pollute_list:\n",
                "    process_conti_data(target_pollute,target_modes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "''"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "str()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pytorch",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "f70219513a060e8f23e2b57c5836658fd454fe019e317ec5458f3d53dbcb0b52"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
