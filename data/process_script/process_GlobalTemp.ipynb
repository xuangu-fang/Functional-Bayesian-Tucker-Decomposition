{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import glob\n",
                "import matplotlib.pyplot as plt\n",
                "import collections\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(0)\n",
                "\n",
                "path_city = r'/data/fang/data/GloabalTemp/raw/GlobalLandTemperaturesByCity.csv' # use your path\n",
                "path_major_city = r'/data/fang/data/GloabalTemp/raw/GlobalLandTemperaturesByMajorCity.csv' # use your path\n",
                "\n",
                "# colnames=['dt', 'Latitude', 'Longitude', 'Country','AverageTemperature'] \n",
                "mynames=['dt', 'Latitude', 'Longitude', 'AverageTemperature', 'City', 'Country', 'MajorCity']\n",
                "\n",
                "df1 = pd.read_csv(path_city, index_col=None, header=0)\n",
                "df2 = pd.read_csv(path_major_city,index_col=None, header=0)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "there are 248 unique cities in United States\n",
                        "there are 371 unique cities in China\n",
                        "               dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
                        "47555  1820-01-01               2.101                          3.217  Abilene   \n",
                        "47556  1820-02-01               6.926                          2.853  Abilene   \n",
                        "47557  1820-03-01              10.767                          2.395  Abilene   \n",
                        "47558  1820-04-01              17.989                          2.202  Abilene   \n",
                        "47559  1820-05-01              21.809                          2.036  Abilene   \n",
                        "\n",
                        "             Country Latitude Longitude  \n",
                        "47555  United States   32.95N   100.53W  \n",
                        "47556  United States   32.95N   100.53W  \n",
                        "47557  United States   32.95N   100.53W  \n",
                        "47558  United States   32.95N   100.53W  \n",
                        "47559  United States   32.95N   100.53W  \n",
                        "   year Latitude Longitude              City  AverageTemperature\n",
                        "0  1743   28.13N    80.91W           Orlando              18.722\n",
                        "1  1743   28.13N    82.73W        Clearwater              18.664\n",
                        "2  1743   28.13N    82.73W  Saint Petersburg              18.664\n",
                        "3  1743   28.13N    82.73W             Tampa              18.664\n",
                        "4  1743   29.74N    81.23W      Jacksonville              17.550\n",
                        "               year  AverageTemperature           lat           lon\n",
                        "count  55944.000000        55944.000000  55944.000000  55944.000000\n",
                        "mean    1900.194570           57.014787     36.840027     95.039363\n",
                        "std       70.074467            8.677388      5.015264     16.646471\n",
                        "min     1743.000000            7.190600     26.520000     72.000000\n",
                        "25%     1850.000000           49.714487     32.950000     80.950000\n",
                        "50%     1905.000000           57.855500     36.170000     90.460000\n",
                        "75%     1959.000000           62.742650     40.990000    112.020000\n",
                        "max     2013.000000           82.414400     61.880000    151.130000\n"
                    ]
                }
            ],
            "source": [
                "# check the unique city of united states\n",
                "print('there are %d unique cities in United States' % len(df1[df1['Country']=='United States']['City'].unique()))\n",
                "\n",
                "# check the unique city of china\n",
                "print('there are %d unique cities in China' % len(df1[df1['Country']=='China']['City'].unique()))\n",
                "\n",
                "# get the data of united states and clean missing data of temperature\n",
                "df_us = df1[df1['Country']=='United States']\n",
                "df_us = df_us.dropna()\n",
                "print(df_us.head())\n",
                "\n",
                "# convert the date to datetime format year\n",
                "df_us['dt'] = pd.to_datetime(df_us['dt'])\n",
                "df_us['year'] = df_us['dt'].dt.year\n",
                "\n",
                "# aggregate the temperature by year and latitude and longitude, drop the uncertainty\n",
                "df_us = df_us.drop(['AverageTemperatureUncertainty'], axis=1)\n",
                "df_us = df_us.groupby(['year','Latitude','Longitude','City']).mean().reset_index()\n",
                "print(df_us.head())\n",
                "\n",
                "# convert the latitude and longitude from str to float\n",
                "df_us['lat'] = df_us['Latitude'].apply(lambda x: float(x[:-1]))\n",
                "df_us['lon'] = df_us['Longitude'].apply(lambda x: float(x[:-1]))\n",
                "df_us = df_us.drop(['Latitude','Longitude'], axis=1)\n",
                "\n",
                "# normalize the temperature\n",
                "# df_us['AverageTemperature'] = (df_us['AverageTemperature'] - df_us['AverageTemperature'].mean()) / df_us['AverageTemperature'].std()\n",
                "\n",
                "# celsius to fahrenheit\n",
                "df_us['AverageTemperature'] = df_us['AverageTemperature'] * 9/5 + 32\n",
                "\n",
                "# summarize the df_us\n",
                "print(df_us.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_6499/3156536237.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
                        "  df_us[df_us['lon']<115][df_us['lon']>100]['City'].unique()\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "array(['Fort Collins', 'Aurora', 'Colorado Springs', 'Denver',\n",
                            "       'Highlands Ranch', 'Lakewood', 'Thornton', 'Westminster',\n",
                            "       'Abilene', 'Lubbock', 'Amarillo', 'Albuquerque', 'Pueblo',\n",
                            "       'Arvada', 'Salt Lake City', 'West Jordan', 'West Valley City',\n",
                            "       'El Paso', 'Provo', 'Nogales', 'Tucson', 'Chandler', 'Gilbert',\n",
                            "       'Glendale', 'Mesa', 'Peoria', 'Phoenix', 'Scottsdale', 'Tempe'],\n",
                            "      dtype=object)"
                        ]
                    },
                    "execution_count": 49,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_us\n",
                "# find city with lon in the range of 76.85 and 85\n",
                "# df_us[df_us['lon']<82][df_us['lon']>76.85]['City'].unique()\n",
                "# df_us[df_us['lon']<130][df_us['lon']>120]['City'].unique()\n",
                "df_us[df_us['lon']<115][df_us['lon']>100]['City'].unique()\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array(['Minneapolis', 'Saint Paul', 'Portland', 'Vancouver'], dtype=object)"
                        ]
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_us[df_us['lat']== 45.81]['City'].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "lat 15\n",
                        "lon 95\n",
                        "year 267\n"
                    ]
                }
            ],
            "source": [
                "def make_continues_mode(df, mode, normalize=10):\n",
                "\n",
                "    target_df = df[mode]\n",
                "    if normalize:\n",
                "        df[mode+'_CONTI'] = normalize* (target_df-target_df.min())/(target_df.max()-target_df.min())\n",
                "\n",
                "        # use dict to map the normalized value to the original value\n",
                "        NORMAL_2_RAW_dict = {norm_value:real_value for norm_value,real_value in zip(np.sort(df[mode+'_CONTI'].unique()),np.sort(target_df.unique()))}\n",
                "\n",
                "        RAW_2_NORMAL_dict = {real_value:norm_value for norm_value,real_value in zip(np.sort(df[mode+'_CONTI'].unique()),np.sort(target_df.unique()))}\n",
                "        \n",
                "\n",
                "\n",
                "    df[mode+'_DISCT'],CONTI_2_DISCT_dict,DISCT_2_CONTI_dict = unique_recoding(df[mode+'_CONTI'])\n",
                "    print(mode,len(df[mode+'_DISCT'].unique()))\n",
                "\n",
                "    return CONTI_2_DISCT_dict,DISCT_2_CONTI_dict,NORMAL_2_RAW_dict,RAW_2_NORMAL_dict\n",
                "\n",
                "def unique_recoding(target_df):\n",
                "    # colum_name = 'movieId'\n",
                "    unique_key = np.sort(target_df.unique())\n",
                "    CONTI_2_DISCT_dict = {key:id for id,key in enumerate(unique_key)}\n",
                "    DISCT_2_CONTI_dict = {id:key for id,key in enumerate(unique_key)}\n",
                "\n",
                "\n",
                "    new_column = target_df.apply(lambda x:CONTI_2_DISCT_dict[x])\n",
                "    # data[colum_name] = new_column\n",
                "    # print('ndim of %s is %d'%(colum_name,len(new_column.unique())))\n",
                "    return new_column,CONTI_2_DISCT_dict,DISCT_2_CONTI_dict\n",
                "\n",
                "CONTI_2_DISCT_dict_list = {}\n",
                "DISCT_2_CONTI_dict_list = {}\n",
                "NORMAL_2_RAW_dict_list = {}\n",
                "RAW_2_NORMAL_dict_list = {}\n",
                "\n",
                "for mode in ['lat','lon','year']:\n",
                "\n",
                "    CONTI_2_DISCT_dict,DISCT_2_CONTI_dict,NORMAL_2_RAW_dict,RAW_2_NORMAL_dict = make_continues_mode(df_us,mode, normalize=1)\n",
                "\n",
                "    CONTI_2_DISCT_dict_list[mode] = CONTI_2_DISCT_dict\n",
                "    DISCT_2_CONTI_dict_list[mode] = DISCT_2_CONTI_dict\n",
                "    NORMAL_2_RAW_dict_list[mode] = NORMAL_2_RAW_dict\n",
                "    RAW_2_NORMAL_dict_list[mode] = RAW_2_NORMAL_dict\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_disct_data(modes_BASE,dims_BASE,target_pollute='AverageTemperature'):\n",
                "    df_base = df_us.copy()\n",
                "\n",
                "    # df_DISCT = df.groupby(['year', 'month', 'day', 'station']).agg({'TEMP':'mean', 'PRES':'mean', 'DEWP':'mean', 'RAIN':'mean', 'wd':lambda x: collections.Counter(''.join(x)).most_common(2)[0][0] + collections.Counter(''.join(x)).most_common(2)[1][0], 'WSPM':'mean', 'PM2.5':'mean'}).reset_index()\n",
                "\n",
                "    for i in range(len(dims_BASE)):\n",
                "        target_mode = modes_BASE[i]\n",
                "        DISCT_dim = dims_BASE[i]\n",
                "        df_base[target_mode + '_BASE'] = pd.cut( df_base[target_mode +'_CONTI'], DISCT_dim).astype('category').cat.codes \n",
                "\n",
                "    target_modes_BASE = [ item + '_BASE' for item in modes_BASE]\n",
                "\n",
                "    # df_base = df_base.groupby(target_modes_BASE).agg({target_pollute:'mean'}).reset_index()\n",
                "\n",
                "    ndims = [df_base[mode].max()+1 for mode in target_modes_BASE]\n",
                "    \n",
                "\n",
                "    N = len(df_base)\n",
                "    print(ndims, ' N=',N)\n",
                "    Ntr = int(N * 0.8)\n",
                "    idx = np.arange(N)\n",
                "    folds = []\n",
                "\n",
                "    for i in range(5):\n",
                "        np.random.shuffle(idx)\n",
                "        tr_idx = idx[:Ntr]\n",
                "        tr_y = df_base[target_pollute][tr_idx].values\n",
                "        tr_ind = df_base[target_modes_BASE].values[tr_idx,:]\n",
                "        \n",
                "        # print('fold=',i)\n",
                "\n",
                "        te_idx = idx[Ntr:]\n",
                "        te_y = df_base[target_pollute][te_idx].values\n",
                "        te_ind = df_base[target_modes_BASE].values[te_idx,:]\n",
                "\n",
                "\n",
                "        folds.append({\n",
                "            'tr_ind': tr_ind,\n",
                "            'tr_y': tr_y,\n",
                "            'te_ind': te_ind,\n",
                "            'te_y': te_y,\n",
                "            'ndims':ndims,\n",
                "        })\n",
                "\n",
                "    data = {'ndims': ndims, 'data': folds}\n",
                "    ndim_str = \"x\".join([str(i) for i in ndims])\n",
                "\n",
                "    print()\n",
                "\n",
                "    dict_name = '../US_temp/'\n",
                "    Path(dict_name).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    # file_name = 'DISCT_' + ndim_str+'_no_agg'+'.npy'\n",
                "    file_name = 'DISCT_' + ndim_str+'.npy'\n",
                "\n",
                "    # print(file_name)\n",
                "    np.save(dict_name + file_name, data)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[15, 95, 267]  N= 55944\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# discretized data with different granularity, use for baseline \n",
                "\n",
                "modes_BASE = ['lat','lon','year']\n",
                "\n",
                "dims_BASE = [15,95,267]\n",
                "\n",
                "process_disct_data(modes_BASE,dims_BASE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[50, 50, 150]  N= 7455\n",
                        "\n",
                        "[100, 100, 300]  N= 10320\n",
                        "\n",
                        "[300, 300, 1000]  N= 11746\n",
                        "\n",
                        "[428, 501, 1461]  N= 11954\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "'''agg-version'''\n",
                "\n",
                "# discretized data with different granularity, use for baseline \n",
                "# target_pollute = 'PM2.5'\n",
                "# modes_BASE = ['TEMP','PRES','time']\n",
                "# dims_BASE = [50,50,50]\n",
                "# # dims_BASE = [428,501,1461] # full\n",
                "\n",
                "# # target_pollute_list = ['PM2.5','PM10','SO2']\n",
                "# target_pollute_list = ['PM10']\n",
                "\n",
                "# dims_BASE_list = [[50,50,150],[100,100,300],[300,300,1000],[428,501,1461] ]\n",
                "\n",
                "# for target_pollute in target_pollute_list:\n",
                "#     for dims_BASE in dims_BASE_list:\n",
                "        \n",
                "#         process_disct_data(modes_BASE,dims_BASE,target_pollute)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df_us.copy()\n",
                "def process_conti_data(target_pollute,target_modes):\n",
                "    modes_DISCT = [mode+'_DISCT' for mode in target_modes]\n",
                "    modes_CONTI = [mode+'_CONTI' for mode in target_modes]\n",
                "\n",
                "    CONTI_2_DISCT_dicts = [CONTI_2_DISCT_dict_list[mode] for mode in target_modes]\n",
                "    DISCT_2_CONTI_dicts = [DISCT_2_CONTI_dict_list[mode] for mode in target_modes]\n",
                "    NORMAL_2_RAW_dicts = [NORMAL_2_RAW_dict_list[mode] for mode in target_modes]\n",
                "    RAW_2_NORMAL_dicts = [RAW_2_NORMAL_dict_list[mode] for mode in target_modes]\n",
                "\n",
                "\n",
                "    ndims = [df[mode].max()+1 for mode in modes_DISCT]\n",
                "    print('ndims:',ndims)\n",
                "\n",
                "    N = len(df)\n",
                "    Ntr = int(N * 0.8)\n",
                "    idx = np.arange(N)\n",
                "    folds = []\n",
                "    for i in range(5):\n",
                "        np.random.shuffle(idx)\n",
                "        tr_idx = idx[:Ntr]\n",
                "        tr_y = df[target_pollute][tr_idx].values\n",
                "        tr_ind_DISCT = df[modes_DISCT].values[tr_idx,:]\n",
                "        tr_ind_CONTI = df[modes_CONTI].values[tr_idx,:]\n",
                "\n",
                "        # print('fold=',i)\n",
                "        # print(len(np.unique(tr_ind_DISCT[:,0])))\n",
                "        # print(len(np.unique(tr_ind_DISCT[:,1])))\n",
                "        # print(len(np.unique(tr_ind_DISCT[:,2])))\n",
                "\n",
                "        te_idx = idx[Ntr:]\n",
                "        te_y = df[target_pollute][te_idx].values\n",
                "        te_ind_DISCT = df[modes_DISCT].values[te_idx,:]\n",
                "        te_ind_CONTI = df[modes_CONTI].values[te_idx,:]\n",
                "\n",
                "        # track the never-seen idx in test data\n",
                "        never_seen_test_idx = []\n",
                "        for mode in range(len(target_modes)):\n",
                "            train_set = set(np.unique(tr_ind_DISCT[:,mode]))\n",
                "            full_set = set(DISCT_2_CONTI_dicts[mode].keys())\n",
                "            never_seen_test_idx.append(list(full_set.difference(train_set)))\n",
                "\n",
                "\n",
                "        folds.append({\n",
                "            'tr_ind_DISCT': tr_ind_DISCT,\n",
                "            'tr_ind_CONTI': tr_ind_CONTI,\n",
                "            'tr_y': tr_y,\n",
                "            'te_ind_DISCT': te_ind_DISCT,\n",
                "            'te_ind_CONTI': te_ind_CONTI,\n",
                "            'te_y': te_y,\n",
                "            'ndims':ndims,\n",
                "            'never_seen_test_idx':never_seen_test_idx\n",
                "        })\n",
                "\n",
                "    data = {'ndims': ndims, 'data': folds,'CONTI_2_DISCT_dicts':CONTI_2_DISCT_dicts, 'DISCT_2_CONTI_dicts':DISCT_2_CONTI_dicts,\n",
                "    'NORMAL_2_RAW_dicts':NORMAL_2_RAW_dicts,\n",
                "    'RAW_2_NORMAL_dicts':RAW_2_NORMAL_dicts}\n",
                "    ndim_str = \"x\".join([str(i) for i in ndims])\n",
                "\n",
                "    dict_name = '../US_temp/'\n",
                "    Path(dict_name).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    file_name = 'CONTI_' + ndim_str +'.npy'\n",
                "\n",
                "    # file_name = 'conti_beijing_15k_'+'_'.join(target_modes)+'_'+target_pollute+'_'+ndim_str+'.npy'\n",
                "    print(file_name)\n",
                "    np.save(dict_name + file_name, data)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ndims: [15, 95, 267]\n",
                        "CONTI_15x95x267.npy\n"
                    ]
                }
            ],
            "source": [
                "target_pollute='AverageTemperature'\n",
                "target_modes = ['lat','lon','year']\n",
                "process_conti_data(target_pollute,target_modes)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pytorch",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "f70219513a060e8f23e2b57c5836658fd454fe019e317ec5458f3d53dbcb0b52"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
